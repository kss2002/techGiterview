"""
GitHub API Integration Router

ì‹¤ì œ GitHub APIì™€ ì—°ë™í•˜ì—¬ ì €ì¥ì†Œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import uuid
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, HTTPException, Depends, Header
from pydantic import BaseModel, HttpUrl
from datetime import datetime
from sqlalchemy import func, String

from app.core.config import settings
from app.services.github_client import GitHubClient
from app.services.local_repository_analyzer import LocalRepositoryAnalyzer
from app.core.database import get_db
from sqlalchemy.orm import Session
from app.agents.repository_analyzer import RepositoryAnalyzer as AgentRepositoryAnalyzer

# ì„ì‹œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
analysis_cache = {}




router = APIRouter()


class RepositoryAnalysisRequest(BaseModel):
    """ì €ì¥ì†Œ ë¶„ì„ ìš”ì²­"""
    repo_url: HttpUrl
    store_results: bool = True


class RepositoryInfo(BaseModel):
    """ì €ì¥ì†Œ ê¸°ë³¸ ì •ë³´"""
    name: str
    owner: str
    description: Optional[str]
    language: Optional[str]
    stars: int
    forks: int
    size: int
    topics: List[str]
    default_branch: str


class FileInfo(BaseModel):
    """íŒŒì¼ ì •ë³´"""
    path: str
    type: str
    size: int
    content: Optional[str] = None


class FileTreeNode(BaseModel):
    """íŒŒì¼ íŠ¸ë¦¬ ë…¸ë“œ"""
    name: str
    path: str
    type: str  # "file" or "dir"
    size: Optional[int] = None
    children: Optional[List['FileTreeNode']] = None

# Forward reference í•´ê²°ì„ ìœ„í•´ ëª¨ë¸ ì—…ë°ì´íŠ¸
FileTreeNode.model_rebuild()


class AnalysisResult(BaseModel):
    """ë¶„ì„ ê²°ê³¼"""
    success: bool
    analysis_id: str
    repo_info: RepositoryInfo
    tech_stack: Dict[str, float]
    key_files: List[FileInfo]
    summary: str
    recommendations: List[str]
    created_at: datetime
    smart_file_analysis: Optional[Dict[str, Any]] = None


@router.post("/analyze", response_model=AnalysisResult)
async def analyze_repository(
    request: RepositoryAnalysisRequest,
    github_token: Optional[str] = Header(None, alias="x-github-token"),
    google_api_key: Optional[str] = Header(None, alias="x-google-api-key")
):
    """ì‹¤ì œ GitHub ì €ì¥ì†Œ ë¶„ì„ - ìƒì„¸ RepositoryAnalyzer ì‚¬ìš©"""
    
    # í—¤ë”ì—ì„œ API í‚¤ ì¶”ì¶œ
    api_keys = {}
    if github_token:
        api_keys["github_token"] = github_token
    if google_api_key:
        api_keys["google_api_key"] = google_api_key
    
    # ìƒì„¸ ë¡œê¹…ì´ í¬í•¨ëœ RepositoryAnalyzer ì‚¬ìš©
    from app.agents.repository_analyzer import RepositoryAnalyzer
    analyzer = RepositoryAnalyzer()
    
    # ê³ ìœ  ë¶„ì„ ID ìƒì„±
    analysis_id = str(uuid.uuid4())
    
    try:
        print(f"[GITHUB_API] ========== ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘ ==========")
        print(f"[GITHUB_API] ìš”ì²­ URL: {request.repo_url}")
        print(f"[GITHUB_API] ë¶„ì„ ID: {analysis_id}")
        print(f"[GITHUB_API] API í‚¤ ì •ë³´: GitHub Token={github_token is not None}, Google API Key={google_api_key is not None}")
        
        # API í‚¤ë¥¼ í¬í•¨í•˜ì—¬ ì‹¤ì œ RepositoryAnalyzer.analyze_repository() ì‚¬ìš©
        analysis_result = await analyzer.analyze_repository(str(request.repo_url), api_keys=api_keys)
        
        if not analysis_result.get("success"):
            raise HTTPException(
                status_code=500, 
                detail=f"Repository analysis failed: {analysis_result.get('error', 'Unknown error')}"
            )
        
        # RepositoryAnalyzer ê²°ê³¼ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        repo_info_data = analysis_result.get("repo_info", {})
        repo_info = RepositoryInfo(
            name=repo_info_data.get("name", ""),
            owner=repo_info_data.get("owner", ""),  # ì§ì ‘ owner í•„ë“œ ì‚¬ìš©
            description=repo_info_data.get("description"),
            language=repo_info_data.get("language"),
            stars=repo_info_data.get("stargazers_count", 0),
            forks=repo_info_data.get("forks_count", 0),
            size=repo_info_data.get("size", 0),
            topics=[],  # TODO: topics ì •ë³´ ì¶”ê°€
            default_branch="main"  # TODO: default_branch ì •ë³´ ì¶”ê°€
        )
        
        # key_files ë³€í™˜
        key_files_data = analysis_result.get("key_files", [])
        key_files = [
            FileInfo(
                path=f.get("path", ""),
                type="file",
                size=f.get("size", 0),
                content=f.get("content")
            )
            for f in key_files_data
        ]
        
        # tech_stackê³¼ smart_file_analysis ê°€ì ¸ì˜¤ê¸°
        tech_stack = analysis_result.get("tech_stack", {})
        smart_file_analysis = analysis_result.get("smart_file_analysis")
        
        # ìš”ì•½ ë° ì¶”ì²œì‚¬í•­
        summary = analysis_result.get("analysis_summary", "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        recommendations = [
            "í”„ë¡œì íŠ¸ì— README.md íŒŒì¼ì„ ì¶”ê°€í•˜ì—¬ í”„ë¡œì íŠ¸ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”.",
            "í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
            "Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ í™˜ê²½ì„ í‘œì¤€í™”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
            "GitHub Actionsì„ ì‚¬ìš©í•˜ì—¬ CI/CD íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•´ë³´ì„¸ìš”."
        ]
        
        print(f"[GITHUB_API] ë¶„ì„ ì™„ë£Œ - ê¸°ìˆ ìŠ¤íƒ: {len(tech_stack)}ê°œ, í•µì‹¬íŒŒì¼: {len(key_files)}ê°œ")
        
        # ê²°ê³¼ ê°ì²´ ìƒì„±
        result = AnalysisResult(
            success=True,
            analysis_id=analysis_id,
            repo_info=repo_info,
            tech_stack=tech_stack,
            key_files=key_files,
            summary=summary,
            recommendations=recommendations,
            created_at=datetime.utcnow(),
            smart_file_analysis=smart_file_analysis
        )
        
        # ì„ì‹œ ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
        analysis_cache[analysis_id] = result
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


@router.get("/analysis/recent")
async def get_recent_analyses(limit: int = 5, db: Session = Depends(get_db)):
    """ìµœê·¼ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¡°íšŒ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜, ì¶”ì •ì¹˜ ë¯¸ì‚¬ìš©)"""
    try:
        # ê°œë°œ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€ í™•ì¸
        from app.core.config import is_development_mode_active
        if not is_development_mode_active():
            print(f"[RECENT_ANALYSES] ê°œë°œ ëª¨ë“œ ë¹„í™œì„±í™” - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return {
                "success": True,
                "data": [],
                "message": "Development mode is disabled. Recent analyses are not available."
            }
        
        print(f"[RECENT_ANALYSES] ìµœê·¼ ë¶„ì„ ìš”ì²­ - limit: {limit}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì™„ë£Œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        from app.models.repository import RepositoryAnalysis
        from sqlalchemy import desc

        recent_analyses_db = db.query(RepositoryAnalysis)\
            .filter(RepositoryAnalysis.status == "completed")\
            .order_by(desc(RepositoryAnalysis.created_at))\
            .limit(limit)\
            .all()
        
        final_analyses = []
        
        for analysis in recent_analyses_db:
            # URLì—ì„œ owner/repo ì¶”ì¶œ
            url_parts = analysis.repository_url.replace("https://github.com/", "").split("/")
            repo_owner = url_parts[0] if len(url_parts) > 0 else "Unknown"
            repo_name = url_parts[1] if len(url_parts) > 1 else analysis.repository_name or "Unknown"
            
            # ê¸°ìˆ  ìŠ¤íƒ ì •ë³´ ì²˜ë¦¬ (ì‹¤ë°ì´í„°ë§Œ)
            tech_stack_dict = analysis.tech_stack if analysis.tech_stack else {}
            tech_stack = list(tech_stack_dict.keys())[:3]

            final_analyses.append({
                "analysis_id": analysis.id.hex if hasattr(analysis.id, 'hex') else str(analysis.id).replace('-', ''),
                "repository_name": repo_name,
                "repository_owner": repo_owner,
                "primary_language": analysis.primary_language or "Unknown",
                "created_at": analysis.created_at.isoformat(),
                "tech_stack": tech_stack,
                "file_count": analysis.file_count or 0
            })
        
        print(f"[RECENT_ANALYSES] ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(final_analyses)}ê°œ ë¶„ì„ ë°˜í™˜")
        
        return {
            "success": True,
            "data": final_analyses,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"[RECENT_ANALYSES] Error: {e}")
        return {
            "success": False,
            "data": [],
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


@router.get("/analysis/{analysis_id}", response_model=AnalysisResult)
async def get_analysis_result(analysis_id: str, db: Session = Depends(get_db)):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ - ë©”ëª¨ë¦¬ ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ"""
    try:
        # UUID ê²€ì¦
        uuid.UUID(analysis_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid analysis ID format")
    
    # 1. ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ (ìš°ì„ )
    if analysis_id in analysis_cache:
        return analysis_cache[analysis_id]
    
    # 2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ (í´ë°±)
    try:
        from app.models.repository import RepositoryAnalysis
        
        # SQLiteì—ì„œëŠ” UUIDê°€ ë¬¸ìì—´ë¡œ ì €ì¥ë˜ë¯€ë¡œ ë¬¸ìì—´ ë¹„êµ ì‚¬ìš©
        # í•˜ì´í”ˆì´ ìˆëŠ” í˜•íƒœì™€ ì—†ëŠ” í˜•íƒœ ëª¨ë‘ ì‹œë„
        analysis_id_no_hyphens = analysis_id.replace('-', '')
        analysis_db = db.query(RepositoryAnalysis)\
            .filter(
                func.cast(RepositoryAnalysis.id, String).in_([analysis_id, analysis_id_no_hyphens])
            )\
            .first()
        
        if not analysis_db:
            raise HTTPException(status_code=404, detail="Analysis not found")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê²°ê³¼ë¥¼ AnalysisResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        repo_url_parts = analysis_db.repository_url.replace("https://github.com/", "").split("/")
        owner = repo_url_parts[0] if len(repo_url_parts) > 0 else "Unknown"
        repo_name = repo_url_parts[1] if len(repo_url_parts) > 1 else "Unknown"
        
        repo_info = RepositoryInfo(
            name=repo_name,
            owner=owner,
            description=f"{owner}/{repo_name} repository",
            language=analysis_db.primary_language or "Unknown",
            stars=0,  # ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
            forks=0,
            size=0,
            topics=[],
            default_branch="main"
        )
        
        # ê¸°ë³¸ íŒŒì¼ ì •ë³´ (ì‹¤ì œë¡œëŠ” ë³„ë„ í…Œì´ë¸”ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        key_files = []
        
        # ê¸°ìˆ  ìŠ¤íƒ ì •ë³´
        tech_stack = analysis_db.tech_stack if analysis_db.tech_stack else {}
        
        analysis_result = AnalysisResult(
            success=True,
            analysis_id=str(analysis_db.id),
            repo_info=repo_info,
            tech_stack=tech_stack,
            key_files=key_files,
            summary=f"{repo_name} ì €ì¥ì†Œ ë¶„ì„ ê²°ê³¼",
            recommendations=[
                "í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
                "Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ í™˜ê²½ì„ í‘œì¤€í™”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
                "GitHub Actionsì„ ì‚¬ìš©í•˜ì—¬ CI/CD íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•´ë³´ì„¸ìš”."
            ],
            created_at=analysis_db.created_at
        )
        
        # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥ (ë‹¤ìŒë²ˆ ì¡°íšŒ ìµœì í™”)
        analysis_cache[analysis_id] = analysis_result
        
        return analysis_result
        
    except Exception as e:
        print(f"[DB_FALLBACK] Error loading from database: {e}")
        raise HTTPException(status_code=404, detail="Analysis not found")


@router.get("/analysis/{analysis_id}/all-files", response_model=List[FileTreeNode])
async def get_all_repository_files(
    analysis_id: str,
    max_depth: int = 3,
    max_files: int = 500,
    db: Session = Depends(get_db)
):
    """ë¶„ì„ëœ ì €ì¥ì†Œì˜ ëª¨ë“  íŒŒì¼ íŠ¸ë¦¬ êµ¬ì¡° ì¡°íšŒ"""
    try:
        # UUID ê²€ì¦
        uuid.UUID(analysis_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid analysis ID format")
    
    analyzer = LocalRepositoryAnalyzer()
    
    try:
        owner = None
        repo = None

        # 1. ë©”ëª¨ë¦¬ ìºì‹œ ìš°ì„ 
        if analysis_id in analysis_cache:
            analysis_result = analysis_cache[analysis_id]
            owner = analysis_result.repo_info.owner
            repo = analysis_result.repo_info.name
        else:
            # 2. DB í´ë°±
            from app.models.repository import RepositoryAnalysis
            analysis_db = db.query(RepositoryAnalysis).filter(
                func.cast(RepositoryAnalysis.id, String).in_([analysis_id, analysis_id.replace('-', '')])
            ).first()
            if not analysis_db:
                raise HTTPException(status_code=404, detail="Analysis not found")

            repo_url_parts = analysis_db.repository_url.replace("https://github.com/", "").split("/")
            owner = repo_url_parts[0] if len(repo_url_parts) > 0 else None
            repo = repo_url_parts[1] if len(repo_url_parts) > 1 else None

        if not owner or not repo:
            raise HTTPException(status_code=404, detail="Repository information not found")
        
        # ëª¨ë“  íŒŒì¼ì„ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ê°€ì ¸ì˜¤ê¸°
        file_tree = await analyzer.get_all_files(owner, repo, max_depth, max_files)
        
        return file_tree
        
    except Exception as e:
        error_msg = str(e)
        
        # GitHub API ê´€ë ¨ ì—ëŸ¬ ì²˜ë¦¬
        if "Connection timeout" in error_msg or "timeout" in error_msg.lower():
            raise HTTPException(
                status_code=503, 
                detail="GitHub API ì—°ê²° ì‹œê°„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        elif "404" in error_msg or "not found" in error_msg.lower():
            raise HTTPException(
                status_code=404, 
                detail="ì €ì¥ì†Œ ë˜ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì €ì¥ì†Œ URLì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        elif "403" in error_msg or "forbidden" in error_msg.lower():
            raise HTTPException(
                status_code=403, 
                detail="GitHub API ì ‘ê·¼ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¹„ê³µê°œ ì €ì¥ì†Œì´ê±°ë‚˜ API í† í°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        elif "rate limit" in error_msg.lower() or "429" in error_msg:
            raise HTTPException(
                status_code=429, 
                detail="GitHub API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"
            )


@router.get("/analysis/{analysis_id}/file-content")
async def get_file_content(analysis_id: str, file_path: str):
    """íŠ¹ì • íŒŒì¼ì˜ ë‚´ìš© ì¡°íšŒ - ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ GitHub API ìš”ì²­"""
    try:
        # UUID ê²€ì¦
        uuid.UUID(analysis_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid analysis ID format")
    
    # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    if analysis_id not in analysis_cache:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    analysis_result = analysis_cache[analysis_id]
    
    try:
        # 1. ë¨¼ì € ìºì‹œëœ íŒŒì¼ ëª©ë¡ì—ì„œ ë‚´ìš© ì°¾ê¸°
        cached_content = None
        cached_file_info = None
        
        # smart_file_analysisì—ì„œ ì°¾ê¸°
        if hasattr(analysis_result, 'smart_file_analysis') and analysis_result.smart_file_analysis:
            smart_files = analysis_result.smart_file_analysis.get('files', [])
            for file_info in smart_files:
                if file_info.get('file_path') == file_path or file_info.get('path') == file_path:
                    cached_content = file_info.get('content')
                    cached_file_info = file_info
                    break
        
        # key_filesì—ì„œë„ ì°¾ê¸°
        if not cached_content and hasattr(analysis_result, 'key_files'):
            for file_info in analysis_result.key_files:
                if (hasattr(file_info, 'path') and file_info.path == file_path) or \
                   (isinstance(file_info, dict) and file_info.get('path') == file_path):
                    cached_content = getattr(file_info, 'content', None) or file_info.get('content')
                    cached_file_info = file_info
                    break
        
        # 2. ìºì‹œëœ ë‚´ìš©ì´ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        if cached_content and not cached_content.startswith('# File'):
            file_extension = file_path.split('.')[-1].lower() if '.' in file_path else ''
            file_size = len(cached_content)
            
            # íŒŒì¼ í¬ê¸° ì œí•œ ì—†ìŒ - ì „ì²´ ë‚´ìš© í‘œì‹œ
            
            return {
                "success": True,
                "file_path": file_path,
                "content": cached_content,
                "size": file_size,
                "extension": file_extension,
                "is_binary": False,
                "source": "cache"  # ìºì‹œì—ì„œ ê°€ì ¸ì™”ìŒì„ í‘œì‹œ
            }
        
        # 3. ìºì‹œì— ì—†ìœ¼ë©´ GitHub APIì—ì„œ ê°€ì ¸ì˜¤ê¸° (fallback)
        print(f"[FILE_CONTENT] ìºì‹œì— ì—†ëŠ” íŒŒì¼, GitHub API ìš”ì²­: {file_path}")
        analyzer = LocalRepositoryAnalyzer()
        owner = analysis_result.repo_info.owner
        repo = analysis_result.repo_info.name
        
        content = await analyzer.get_file_content(owner, repo, file_path)
        
        if content is None:
            raise HTTPException(status_code=404, detail="File not found or is binary")
        
        # íŒŒì¼ í¬ê¸° ì œí•œ ì—†ìŒ - ì „ì²´ ë‚´ìš© í‘œì‹œ
        
        # íŒŒì¼ ì •ë³´ ì¶”ê°€
        file_extension = file_path.split('.')[-1].lower() if '.' in file_path else ''
        
        return {
            "success": True,
            "file_path": file_path,
            "content": content,
            "size": len(content),
            "extension": file_extension,
            "is_binary": False,
            "source": "github_api"  # GitHub APIì—ì„œ ê°€ì ¸ì™”ìŒì„ í‘œì‹œ
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch file content: {str(e)}")


@router.get("/analysis", response_model=List[Dict[str, Any]])
async def list_analyses(skip: int = 0, limit: int = 10):
    """ë¶„ì„ íˆìŠ¤í† ë¦¬ ëª©ë¡ ì¡°íšŒ"""
    # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ëª©ë¡ ì¡°íšŒ
    analyses_list = []
    for analysis_id, result in analysis_cache.items():
        analyses_list.append({
            "analysis_id": analysis_id,
            "repository_url": f"https://github.com/{result.repo_info.owner}/{result.repo_info.name}",
            "repository_name": f"{result.repo_info.owner}/{result.repo_info.name}",
            "primary_language": result.repo_info.language,
            "complexity_score": 5.0,  # ì„ì‹œê°’
            "created_at": result.created_at,
            "status": "completed"
        })
    
    # ë‚ ì§œìˆœ ì •ë ¬ ë° í˜ì´ì§€ë„¤ì´ì…˜
    analyses_list.sort(key=lambda x: x["created_at"], reverse=True)
    return analyses_list[skip:skip + limit]



@router.get("/test")
async def test_github_connection():
    """GitHub API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    client = GitHubClient()
    
    try:
        # ê³µê°œ ì €ì¥ì†Œë¡œ í…ŒìŠ¤íŠ¸
        async with client as github_client:
            repo_data = await github_client.get_repository_info("https://github.com/octocat/Hello-World")
        return {
            "success": True,
            "message": "GitHub API connection successful",
            "test_repo": repo_data["name"],
            "authenticated": "Authorization" in client.headers
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"GitHub API connection failed: {str(e)}",
            "authenticated": "Authorization" in client.headers
        }


@router.post("/analyze-simple", response_model=AnalysisResult)
async def analyze_repository_simple(
    request: RepositoryAnalysisRequest,
    github_token: Optional[str] = Header(None, alias="x-github-token"),
    google_api_key: Optional[str] = Header(None, alias="x-google-api-key"),
    db: Session = Depends(get_db)
):
    """ê°„ë‹¨í•œ ì €ì¥ì†Œ ë¶„ì„ - ìºì‹œ ì €ì¥ í¬í•¨"""
    try:
        # URL ìœ íš¨ì„± ê²€ì¦
        repo_url_str = str(request.repo_url)
        if not repo_url_str.startswith("https://github.com/"):
            raise HTTPException(status_code=400, detail="ì˜¬ë°”ë¥¸ GitHub URLì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        # URLì—ì„œ ì†Œìœ ìì™€ ì €ì¥ì†Œ ì´ë¦„ ì¶”ì¶œ
        parts = repo_url_str.replace("https://github.com/", "").split("/")
        if len(parts) < 2:
            raise HTTPException(status_code=400, detail="ì €ì¥ì†Œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        owner, repo_name = parts[0], parts[1]
        analysis_id = str(uuid.uuid4())
        
        print(f"[ANALYZE_SIMPLE] ========== ì‹¤ì œ GitHub API ë¶„ì„ ì‹œì‘ ==========")
        print(f"[ANALYZE_SIMPLE] ì €ì¥ì†Œ: {owner}/{repo_name}")
        print(f"[ANALYZE_SIMPLE] ë¶„ì„ ID: {analysis_id}")
        print(f"[ANALYZE_SIMPLE] ë°›ì€ í—¤ë”:")
        print(f"[ANALYZE_SIMPLE]   - GitHub Token: {'ìˆìŒ' if github_token else 'ì—†ìŒ'}")
        print(f"[ANALYZE_SIMPLE]   - Google API Key: {'ìˆìŒ' if google_api_key else 'ì—†ìŒ'}")
        if github_token:
            print(f"[ANALYZE_SIMPLE]   - GitHub Token ê°’: {github_token[:20]}...")
        if google_api_key:
            print(f"[ANALYZE_SIMPLE]   - Google API Key ê°’: {google_api_key[:20]}...")
        
        # ì‹¤ì œ GitHub APIë¥¼ ì‚¬ìš©í•œ ë¶„ì„ (í—¤ë”ì—ì„œ ë°›ì€ í† í° ì‚¬ìš©)
        
        # [ADVANCED ANALYZER] AgentRepositoryAnalyzer ì‚¬ìš© (PageRank + Hybrid Selection)
        print(f"[ANALYZE_SIMPLE] ê³ ê¸‰ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œì‘...")
        
        # AgentAnalyzerëŠ” ë‚´ë¶€ì ìœ¼ë¡œ GitHubClientë¥¼ ì´ˆê¸°í™”í•˜ì§€ë§Œ, í† í° ì„¤ì •ì´ í•„ìš”í•¨
        analyzer = AgentRepositoryAnalyzer()
        
        # API í‚¤ ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
        api_keys = {}
        if github_token and github_token != "your_github_token_here":
            api_keys["github_token"] = github_token
        
        # Agent ì‹¤í–‰
        agent_result = await analyzer.analyze_repository(repo_url_str, api_keys, use_advanced=True)
        
        if not agent_result or not agent_result.get("success", True):
             error_msg = agent_result.get("error", "Unknown error in agent analysis")
             raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {error_msg}")
             
        # ê²°ê³¼ ë§¤í•‘ (Dict -> Pydantic Models)
        
        # 1. RepositoryInfo
        repo_info_data = agent_result.get("repo_info", {})
        owner_name = repo_info_data.get("owner", {}).get("login", owner) if isinstance(repo_info_data.get("owner"), dict) else repo_info_data.get("owner", owner)
        
        repo_info = RepositoryInfo(
            name=repo_info_data.get("name", repo_name),
            owner=owner_name,
            description=repo_info_data.get("description", "") or f"{owner_name}/{repo_name}",
            language=repo_info_data.get("language") or "Unknown",
            stars=repo_info_data.get("stargazers_count", 0),
            forks=repo_info_data.get("forks_count", 0),
            size=repo_info_data.get("size", 0),
            topics=repo_info_data.get("topics", []),
            default_branch=repo_info_data.get("default_branch", "main")
        )
        
        # 2. Key Files (Dict List -> FileInfo List)
        raw_files = agent_result.get("key_files", []) or agent_result.get("analysis_result", {}).get("key_files", [])
        # Agent result structure might vary, check implementation
        if not raw_files and "important_files" in agent_result:
             raw_files = agent_result["important_files"]
             
        key_files = []
        for f in raw_files:
             # Agent might return full dict or FileInfo object (if mixed)
             # But analyze_repository returns dict mainly.
             if isinstance(f, dict):
                 key_files.append(FileInfo(
                     path=f.get("path"),
                     type=f.get("type", "file"),
                     size=f.get("size", 0),
                     content=f.get("content")
                 ))
             elif hasattr(f, "path"): # It might be an object
                 key_files.append(FileInfo(
                     path=f.path,
                     type=getattr(f, "type", "file"),
                     size=getattr(f, "size", 0),
                     content=getattr(f, "content", None)
                 ))

        # 3. Tech Stack
        tech_stack = agent_result.get("tech_stack", {}) or {}
        
        # 4. Summary & Recommendations
        summary = agent_result.get("analysis_result", {}).get("summary", "") or agent_result.get("summary", "")
        if not summary and "analysis_result" in agent_result:
             summary = agent_result["analysis_result"].get("summary", "")
             
        recommendations = agent_result.get("analysis_result", {}).get("recommendations", []) or agent_result.get("recommendations", [])
        if not recommendations and "analysis_result" in agent_result:
             recommendations = agent_result["analysis_result"].get("recommendations", [])
             
        # 5. Complexity
        complexity_score = agent_result.get("complexity_score", 0.0)
        
        # AnalysisResult ê°ì²´ ìƒì„±
        analysis_result = AnalysisResult(
            success=True,
            analysis_id=analysis_id,
            repo_info=repo_info,
            tech_stack=tech_stack,
            key_files=key_files,
            summary=summary,
            recommendations=recommendations,
            created_at=datetime.now(),
            smart_file_analysis=agent_result.get("smart_file_analysis")
        )
        
        print(f"[ANALYZE_SIMPLE] ê³ ê¸‰ ë¶„ì„ ì™„ë£Œ - íŒŒì¼: {len(key_files)}ê°œ, ê¸°ìˆ ìŠ¤íƒ: {len(tech_stack)}ê°œ, ë³µì¡ë„: {complexity_score}")
        
        # analysis_cacheì— ì €ì¥í•˜ì—¬ ëŒ€ì‹œë³´ë“œì—ì„œ ì¡°íšŒ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        analysis_cache[analysis_id] = analysis_result
        
        print(f"[ANALYZE_SIMPLE] ë¶„ì„ ê²°ê³¼ ìºì‹œì— ì €ì¥: {analysis_id}")
        print(f"[ANALYZE_SIMPLE] ìºì‹œ í¬ê¸°: {len(analysis_cache)}")
        
        # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥í•˜ì—¬ ë©´ì ‘ ì‹œì‘ ì‹œ ì¡°íšŒ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        try:
            from app.models.repository import RepositoryAnalysis
            
            # RepositoryAnalysis ê°ì²´ ìƒì„±
            db_analysis = RepositoryAnalysis(
                id=uuid.UUID(analysis_id),
                repository_url=repo_url_str,
                repository_name=f"{repo_info.owner}/{repo_info.name}",
                primary_language=repo_info.language,
                tech_stack=tech_stack,
                file_count=len(key_files),
                complexity_score=complexity_score,
                analysis_metadata={
                    "summary": summary,
                    "recommendations": recommendations,
                    "key_files_count": len(key_files),
                    "created_by": "analyze_simple_api"
                },
                status="completed",
                completed_at=datetime.now()
            )
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            db.add(db_analysis)
            db.commit()
            db.refresh(db_analysis)
            
            print(f"[ANALYZE_SIMPLE] ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì™„ë£Œ: {analysis_id}")
            print(f"[ANALYZE_SIMPLE] DB ì €ì¥ ìƒíƒœ: {db_analysis.status}")
            
        except Exception as e:
            print(f"[ANALYZE_SIMPLE] ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜ (ìºì‹œëŠ” ì •ìƒ): {str(e)}")
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨í•´ë„ ìºì‹œëŠ” ì •ìƒì´ë¯€ë¡œ ê³„ì† ì§„í–‰
        
        return analysis_result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ANALYZE_SIMPLE] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.get("/dashboard/{analysis_id}")
async def get_dashboard_data(analysis_id: str, db: Session = Depends(get_db)):
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
    try:
        analysis_result = analysis_cache.get(analysis_id)
        if analysis_result is None:
            from app.models.repository import RepositoryAnalysis
            analysis_db = db.query(RepositoryAnalysis).filter(
                func.cast(RepositoryAnalysis.id, String).in_([analysis_id, analysis_id.replace('-', '')])
            ).first()
            if not analysis_db:
                raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            repo_url_parts = analysis_db.repository_url.replace("https://github.com/", "").split("/")
            owner = repo_url_parts[0] if len(repo_url_parts) > 0 else "Unknown"
            repo_name = repo_url_parts[1] if len(repo_url_parts) > 1 else "Unknown"

            repo_info = RepositoryInfo(
                name=repo_name,
                owner=owner,
                description=f"{owner}/{repo_name} repository",
                language=analysis_db.primary_language or "Unknown",
                stars=0,
                forks=0,
                size=0,
                topics=[],
                default_branch="main"
            )
            analysis_result = AnalysisResult(
                success=True,
                analysis_id=str(analysis_db.id),
                repo_info=repo_info,
                tech_stack=analysis_db.tech_stack or {},
                key_files=[],
                summary=(analysis_db.analysis_metadata or {}).get("summary", f"{repo_name} ì €ì¥ì†Œ ë¶„ì„ ê²°ê³¼"),
                recommendations=(analysis_db.analysis_metadata or {}).get("recommendations", []),
                created_at=analysis_db.created_at
            )
        
        print(f"[DASHBOARD] ë¶„ì„ ID {analysis_id} ì¡°íšŒ - íŒŒì¼ ìˆ˜: {len(analysis_result.key_files)}ê°œ")
        
        # AnalysisResult ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return {
            "success": True,
            "analysis_id": analysis_result.analysis_id,
            "repo_info": analysis_result.repo_info.dict() if hasattr(analysis_result.repo_info, 'dict') else analysis_result.repo_info,
            "tech_stack": analysis_result.tech_stack,
            "key_files": [
                {
                    "path": f.path,
                    "type": f.type,
                    "size": f.size,
                    "content": f.content
                } for f in analysis_result.key_files
            ] if analysis_result.key_files else [],
            "summary": analysis_result.summary,
            "recommendations": analysis_result.recommendations,
            "created_at": analysis_result.created_at.isoformat() if hasattr(analysis_result.created_at, 'isoformat') else str(analysis_result.created_at)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[DASHBOARD] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/debug/cache")
async def debug_cache():
    """ë©”ëª¨ë¦¬ ìºì‹œ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    if not settings.debug:
        raise HTTPException(status_code=404, detail="Not found")
    return {
        "cache_size": len(analysis_cache),
        "cached_analysis_ids": list(analysis_cache.keys()),
        "analysis_details": [
            {
                "id": analysis_id,
                "repo": f"{result.repo_info.owner}/{result.repo_info.name}",
                "created_at": result.created_at.isoformat()
            }
            for analysis_id, result in analysis_cache.items()
        ]
    }


@router.delete("/debug/cache")
async def clear_cache():
    """ë©”ëª¨ë¦¬ ìºì‹œ ì´ˆê¸°í™” (ë””ë²„ê¹…ìš©)"""
    if not settings.debug:
        raise HTTPException(status_code=404, detail="Not found")
    cache_size_before = len(analysis_cache)
    analysis_cache.clear()
    
    return {
        "message": "ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤",
        "cleared_items": cache_size_before,
        "current_cache_size": len(analysis_cache)
    }
